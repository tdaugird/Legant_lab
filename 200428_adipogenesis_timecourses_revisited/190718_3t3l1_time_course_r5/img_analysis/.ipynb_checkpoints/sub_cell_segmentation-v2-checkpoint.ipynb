{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is exploratory script to try and generate good segmented cebp beta blobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage import io\n",
    "from skimage import measure\n",
    "from scipy.ndimage.filters import gaussian_laplace\n",
    "from skimage.filters import gaussian\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.exposure import rescale_intensity\n",
    "import easygui\n",
    "from numba import jit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dapi_segm_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f1e2f50aabc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdapi_segm_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dapi_segm_dir' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir(dapi_segm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_img_dir = r'Z:\\TAD\\200428_adipogenesis_timecourses_revisited\\190718_3t3l1_time_course_r5\\filtered_segm_imgs' #directory of segmented images\n",
    "cebp_segm_dir = r'Z:\\TAD\\200428_adipogenesis_timecourses_revisited\\190718_3t3l1_time_course_r5\\cebp_segm_imgs2'\n",
    "dapi_segm_dir = r'Z:\\TAD\\200428_adipogenesis_timecourses_revisited\\190718_3t3l1_time_course_r5\\dapi_segm_imgs2'\n",
    "orig_img_dir_base = r'Z:\\TAD\\190718_3t3l1_time_course_r5' #directory that has subdirectories with original images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this is function adapted taken from:\n",
    "https://github.com/AllenInstitute/aics-segmentation/blob/master/aicssegmentation/core/seg_dot.py'''\n",
    "\n",
    "def dot_2d(struct_img, s2_param):\n",
    "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
    "    for fid in range(len(s2_param)):\n",
    "        log_sigma = s2_param[fid][0]\n",
    "        responce = np.zeros_like(struct_img)\n",
    "        responce = -1*(log_sigma**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma)\n",
    "        bw = np.logical_or(bw, responce>s2_param[fid][1])\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this is function to find cebp beta blobs'''\n",
    "\n",
    "def cebp_blobs(img_, image_scaling_parms = [.5, 10], gaussian_sigma = 1, s2_params = [[1.0, .03]]):\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    intensity_scaling_param = image_scaling_parms\n",
    "    gaussian_smoothing_sigma = gaussian_sigma\n",
    "    ################################\n",
    "    # intensity normalization\n",
    "    struct_img = np.divide(img_, np.max(img_))\n",
    "    \n",
    "    # smoothing with gaussian filter\n",
    "    structure_img_smooth = gaussian(struct_img, sigma=gaussian_smoothing_sigma)\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    s2_param = s2_params\n",
    "    ################################\n",
    "    \n",
    "    bw = dot_2d(structure_img_smooth, s2_param)\n",
    "        #remove small objects\n",
    "    jnk = remove_small_objects(bw)\n",
    "    \n",
    "    return(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebp_used_lst = []\n",
    "dapi_used_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stad3-26-xy1segm_parsed.tiff': 0,\n",
       " 'stad3-26-xy2segm_parsed.tiff': 1,\n",
       " 'stad3-26-xy3segm_parsed.tiff': 2,\n",
       " 'stad3-26-xy4segm_parsed.tiff': 3,\n",
       " 'stad3-26-xy5segm_parsed.tiff': 4,\n",
       " 'stad3-26-xy6segm_parsed.tiff': 5,\n",
       " 'stad3-26-xy7segm_parsed.tiff': 6,\n",
       " 'stad3-26-xy8segm_parsed.tiff': 7,\n",
       " 'stad3-26-xy9segm_parsed.tiff': 8,\n",
       " 'stad3-27-xy1segm_parsed.tiff': 9,\n",
       " 'stad3-27-xy2segm_parsed.tiff': 10,\n",
       " 'stad3-27-xy3segm_parsed.tiff': 11,\n",
       " 'stad3-27-xy4segm_parsed.tiff': 12,\n",
       " 'stad3-27-xy5segm_parsed.tiff': 13,\n",
       " 'stad3-27-xy6segm_parsed.tiff': 14,\n",
       " 'stad3-27-xy7segm_parsed.tiff': 15,\n",
       " 'stad3-27-xy8segm_parsed.tiff': 16,\n",
       " 'stad3-27-xy9segm_parsed.tiff': 17,\n",
       " 'stad3-28-xy1segm_parsed.tiff': 18,\n",
       " 'stad3-28-xy2segm_parsed.tiff': 19,\n",
       " 'stad3-28-xy3segm_parsed.tiff': 20,\n",
       " 'stad3-28-xy4segm_parsed.tiff': 21,\n",
       " 'stad3-28-xy5segm_parsed.tiff': 22,\n",
       " 'stad3-28-xy6segm_parsed.tiff': 23,\n",
       " 'stad3-28-xy7segm_parsed.tiff': 24,\n",
       " 'stad3-28-xy8segm_parsed.tiff': 25,\n",
       " 'stad3-28-xy9segm_parsed.tiff': 26,\n",
       " 'stad3-29-xy1segm_parsed.tiff': 27,\n",
       " 'stad3-29-xy2segm_parsed.tiff': 28,\n",
       " 'stad3-29-xy3segm_parsed.tiff': 29,\n",
       " 'stad3-29-xy4segm_parsed.tiff': 30,\n",
       " 'stad3-29-xy5segm_parsed.tiff': 31,\n",
       " 'stad3-29-xy6segm_parsed.tiff': 32,\n",
       " 'stad3-29-xy8segm_parsed.tiff': 33,\n",
       " 'stad3-29-xy9segm_parsed.tiff': 34,\n",
       " 'stad3-30-xy1segm_parsed.tiff': 35,\n",
       " 'stad3-30-xy2segm_parsed.tiff': 36,\n",
       " 'stad3-30-xy3segm_parsed.tiff': 37,\n",
       " 'stad3-30-xy4segm_parsed.tiff': 38,\n",
       " 'stad3-30-xy5segm_parsed.tiff': 39,\n",
       " 'stad3-30-xy6segm_parsed.tiff': 40,\n",
       " 'stad3-30-xy7segm_parsed.tiff': 41,\n",
       " 'stad3-30-xy8segm_parsed.tiff': 42,\n",
       " 'stad3-30-xy9segm_parsed.tiff': 43,\n",
       " 'stad3-31-xy1segm_parsed.tiff': 44,\n",
       " 'stad3-31-xy2segm_parsed.tiff': 45,\n",
       " 'stad3-31-xy3segm_parsed.tiff': 46,\n",
       " 'stad3-31-xy4segm_parsed.tiff': 47,\n",
       " 'stad3-31-xy5segm_parsed.tiff': 48,\n",
       " 'stad3-31-xy6segm_parsed.tiff': 49,\n",
       " 'stad3-31-xy7segm_parsed.tiff': 50,\n",
       " 'stad3-31-xy8segm_parsed.tiff': 51,\n",
       " 'stad3-31-xy9segm_parsed.tiff': 52,\n",
       " 'stad3-32-xy1segm_parsed.tiff': 53,\n",
       " 'stad3-32-xy2segm_parsed.tiff': 54,\n",
       " 'stad3-32-xy3segm_parsed.tiff': 55,\n",
       " 'stad3-32-xy4segm_parsed.tiff': 56,\n",
       " 'stad3-32-xy5segm_parsed.tiff': 57,\n",
       " 'stad3-32-xy6segm_parsed.tiff': 58,\n",
       " 'stad3-32-xy7segm_parsed.tiff': 59,\n",
       " 'stad3-32-xy8segm_parsed.tiff': 60,\n",
       " 'stad3-32-xy9segm_parsed.tiff': 61,\n",
       " 'stad3-33-xy1segm_parsed.tiff': 62,\n",
       " 'stad3-33-xy2segm_parsed.tiff': 63,\n",
       " 'stad3-33-xy3segm_parsed.tiff': 64,\n",
       " 'stad3-33-xy4segm_parsed.tiff': 65,\n",
       " 'stad3-33-xy5segm_parsed.tiff': 66,\n",
       " 'stad3-33-xy6segm_parsed.tiff': 67,\n",
       " 'stad3-33-xy7segm_parsed.tiff': 68,\n",
       " 'stad3-33-xy8segm_parsed.tiff': 69,\n",
       " 'stad3-33-xy9segm_parsed.tiff': 70,\n",
       " 'stad3-34-xy1segm_parsed.tiff': 71,\n",
       " 'stad3-34-xy2segm_parsed.tiff': 72,\n",
       " 'stad3-34-xy3segm_parsed.tiff': 73,\n",
       " 'stad3-34-xy4segm_parsed.tiff': 74,\n",
       " 'stad3-34-xy5segm_parsed.tiff': 75,\n",
       " 'stad3-34-xy6segm_parsed.tiff': 76,\n",
       " 'stad3-34-xy7segm_parsed.tiff': 77,\n",
       " 'stad3-34-xy8segm_parsed.tiff': 78,\n",
       " 'stad3-34-xy9segm_parsed.tiff': 79,\n",
       " 'stad3-35-xy1segm_parsed.tiff': 80,\n",
       " 'stad3-35-xy2segm_parsed.tiff': 81,\n",
       " 'stad3-35-xy3segm_parsed.tiff': 82,\n",
       " 'stad3-35-xy4segm_parsed.tiff': 83,\n",
       " 'stad3-35-xy5segm_parsed.tiff': 84,\n",
       " 'stad3-35-xy6segm_parsed.tiff': 85,\n",
       " 'stad3-35-xy7segm_parsed.tiff': 86,\n",
       " 'stad3-35-xy8segm_parsed.tiff': 87,\n",
       " 'stad3-35-xy9segm_parsed.tiff': 88,\n",
       " 'stad3-36-xy1segm_parsed.tiff': 89,\n",
       " 'stad3-36-xy2segm_parsed.tiff': 90,\n",
       " 'stad3-36-xy3segm_parsed.tiff': 91,\n",
       " 'stad3-36-xy4segm_parsed.tiff': 92,\n",
       " 'stad3-36-xy5segm_parsed.tiff': 93,\n",
       " 'stad3-36-xy6segm_parsed.tiff': 94,\n",
       " 'stad3-36-xy7segm_parsed.tiff': 95,\n",
       " 'stad3-36-xy8segm_parsed.tiff': 96,\n",
       " 'stad3-36-xy9segm_parsed.tiff': 97,\n",
       " 'stad3-37-xy1segm_parsed.tiff': 98,\n",
       " 'stad3-37-xy2segm_parsed.tiff': 99,\n",
       " 'stad3-37-xy3segm_parsed.tiff': 100,\n",
       " 'stad3-37-xy4segm_parsed.tiff': 101,\n",
       " 'stad3-37-xy5segm_parsed.tiff': 102,\n",
       " 'stad3-37-xy6segm_parsed.tiff': 103,\n",
       " 'stad3-37-xy7segm_parsed.tiff': 104,\n",
       " 'stad3-37-xy8segm_parsed.tiff': 105,\n",
       " 'stad3-37-xy9segm_parsed.tiff': 106,\n",
       " 'stad3-38-xy1segm_parsed.tiff': 107,\n",
       " 'stad3-38-xy2segm_parsed.tiff': 108,\n",
       " 'stad3-38-xy3segm_parsed.tiff': 109,\n",
       " 'stad3-38-xy4segm_parsed.tiff': 110,\n",
       " 'stad3-38-xy5segm_parsed.tiff': 111,\n",
       " 'stad3-38-xy6segm_parsed.tiff': 112,\n",
       " 'stad3-38-xy7segm_parsed.tiff': 113,\n",
       " 'stad3-38-xy8segm_parsed.tiff': 114,\n",
       " 'stad3-38-xy9segm_parsed.tiff': 115,\n",
       " 'stad3-39-xy1segm_parsed.tiff': 116,\n",
       " 'stad3-39-xy2segm_parsed.tiff': 117,\n",
       " 'stad3-39-xy3segm_parsed.tiff': 118,\n",
       " 'stad3-39-xy4segm_parsed.tiff': 119,\n",
       " 'stad3-39-xy5segm_parsed.tiff': 120,\n",
       " 'stad3-39-xy6segm_parsed.tiff': 121,\n",
       " 'stad3-39-xy7segm_parsed.tiff': 122,\n",
       " 'stad3-39-xy8segm_parsed.tiff': 123,\n",
       " 'stad3-39-xy9segm_parsed.tiff': 124,\n",
       " 'stad3-40-xy1segm_parsed.tiff': 125,\n",
       " 'stad3-40-xy2segm_parsed.tiff': 126,\n",
       " 'stad3-40-xy3segm_parsed.tiff': 127,\n",
       " 'stad3-40-xy4segm_parsed.tiff': 128,\n",
       " 'stad3-40-xy5segm_parsed.tiff': 129,\n",
       " 'stad3-40-xy6segm_parsed.tiff': 130,\n",
       " 'stad3-40-xy7segm_parsed.tiff': 131,\n",
       " 'stad3-40-xy8segm_parsed.tiff': 132,\n",
       " 'stad3-40-xy9segm_parsed.tiff': 133,\n",
       " 'stad3-41-xy1segm_parsed.tiff': 134,\n",
       " 'stad3-41-xy2segm_parsed.tiff': 135,\n",
       " 'stad3-41-xy3segm_parsed.tiff': 136,\n",
       " 'stad3-41-xy4segm_parsed.tiff': 137,\n",
       " 'stad3-41-xy5segm_parsed.tiff': 138,\n",
       " 'stad3-41-xy6segm_parsed.tiff': 139,\n",
       " 'stad3-41-xy7segm_parsed.tiff': 140,\n",
       " 'stad3-41-xy8segm_parsed.tiff': 141,\n",
       " 'stad3-41-xy9segm_parsed.tiff': 142,\n",
       " 'stad3-42-xy1segm_parsed.tiff': 143,\n",
       " 'stad3-42-xy2segm_parsed.tiff': 144,\n",
       " 'stad3-42-xy3segm_parsed.tiff': 145,\n",
       " 'stad3-42-xy4segm_parsed.tiff': 146,\n",
       " 'stad3-42-xy5segm_parsed.tiff': 147,\n",
       " 'stad3-42-xy6segm_parsed.tiff': 148,\n",
       " 'stad3-42-xy7segm_parsed.tiff': 149,\n",
       " 'stad3-42-xy8segm_parsed.tiff': 150,\n",
       " 'stad3-42-xy9segm_parsed.tiff': 151,\n",
       " 'stad3-43-xy1segm_parsed.tiff': 152,\n",
       " 'stad3-43-xy2segm_parsed.tiff': 153,\n",
       " 'stad3-43-xy3segm_parsed.tiff': 154,\n",
       " 'stad3-43-xy4segm_parsed.tiff': 155,\n",
       " 'stad3-43-xy5segm_parsed.tiff': 156,\n",
       " 'stad3-43-xy6segm_parsed.tiff': 157,\n",
       " 'stad3-43-xy7segm_parsed.tiff': 158,\n",
       " 'stad3-43-xy8segm_parsed.tiff': 159,\n",
       " 'stad3-43-xy9segm_parsed.tiff': 160,\n",
       " 'stad3-44-xy1segm_parsed.tiff': 161,\n",
       " 'stad3-44-xy2segm_parsed.tiff': 162,\n",
       " 'stad3-44-xy3segm_parsed.tiff': 163,\n",
       " 'stad3-44-xy4segm_parsed.tiff': 164,\n",
       " 'stad3-44-xy5segm_parsed.tiff': 165,\n",
       " 'stad3-44-xy6segm_parsed.tiff': 166,\n",
       " 'stad3-44-xy7segm_parsed.tiff': 167,\n",
       " 'stad3-44-xy8segm_parsed.tiff': 168,\n",
       " 'stad3-44-xy9segm_parsed.tiff': 169,\n",
       " 'stad3-45-xy1segm_parsed.tiff': 170,\n",
       " 'stad3-45-xy2segm_parsed.tiff': 171,\n",
       " 'stad3-45-xy3segm_parsed.tiff': 172,\n",
       " 'stad3-45-xy4segm_parsed.tiff': 173,\n",
       " 'stad3-45-xy5segm_parsed.tiff': 174,\n",
       " 'stad3-45-xy6segm_parsed.tiff': 175,\n",
       " 'stad3-45-xy7segm_parsed.tiff': 176,\n",
       " 'stad3-45-xy8segm_parsed.tiff': 177,\n",
       " 'stad3-45-xy9segm_parsed.tiff': 178,\n",
       " 'stad3-46-xy1segm_parsed.tiff': 179,\n",
       " 'stad3-46-xy2segm_parsed.tiff': 180,\n",
       " 'stad3-46-xy3segm_parsed.tiff': 181,\n",
       " 'stad3-46-xy4segm_parsed.tiff': 182,\n",
       " 'stad3-46-xy5segm_parsed.tiff': 183,\n",
       " 'stad3-46-xy6segm_parsed.tiff': 184,\n",
       " 'stad3-46-xy7segm_parsed.tiff': 185,\n",
       " 'stad3-46-xy8segm_parsed.tiff': 186,\n",
       " 'stad3-46-xy9segm_parsed.tiff': 187,\n",
       " 'stad3-47-xy1segm_parsed.tiff': 188,\n",
       " 'stad3-47-xy2segm_parsed.tiff': 189,\n",
       " 'stad3-47-xy3segm_parsed.tiff': 190,\n",
       " 'stad3-47-xy4segm_parsed.tiff': 191,\n",
       " 'stad3-47-xy5segm_parsed.tiff': 192,\n",
       " 'stad3-47-xy6segm_parsed.tiff': 193,\n",
       " 'stad3-47-xy7segm_parsed.tiff': 194,\n",
       " 'stad3-47-xy8segm_parsed.tiff': 195,\n",
       " 'stad3-47-xy9segm_parsed.tiff': 196,\n",
       " 'stad3-48-xy1segm_parsed.tiff': 197,\n",
       " 'stad3-48-xy2segm_parsed.tiff': 198,\n",
       " 'stad3-48-xy3segm_parsed.tiff': 199,\n",
       " 'stad3-48-xy4segm_parsed.tiff': 200,\n",
       " 'stad3-48-xy5segm_parsed.tiff': 201,\n",
       " 'stad3-48-xy6segm_parsed.tiff': 202,\n",
       " 'stad3-48-xy7segm_parsed.tiff': 203,\n",
       " 'stad3-48-xy8segm_parsed.tiff': 204,\n",
       " 'stad3-48-xy9segm_parsed.tiff': 205}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(segm_img_dir)\n",
    "segm_img_filelist = []\n",
    "for segm_img_filename in os.listdir():\n",
    "    if '.tif' in segm_img_filename:\n",
    "        segm_img_filelist.append(segm_img_filename)\n",
    "image_dict_used_temp = {}\n",
    "for i in range(len(segm_img_filelist)):\n",
    "    image_dict_used_temp.update({segm_img_filelist[i] : i})\n",
    "\n",
    "image_dict_used_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(r'Z:\\TAD\\200428_adipogenesis_timecourses_revisited\\190718_3t3l1_time_course_r5')\n",
    "file_numbers_used = [0, 1, 2, 3, 4, 5, 145, 146, 147]\n",
    "file_numbers_used_df = pd.DataFrame({'file_numbers' : file_numbers_used})\n",
    "file_numbers_used_df.to_csv('file_numbers_used_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell1.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell1.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell2.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell2.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell3.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell3.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell4.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell4.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell5.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell5.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell6.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell6.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell7.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell7.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell8.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell8.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell9.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell9.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell10.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell10.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell11.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell11.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell12.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell12.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell13.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell13.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell14.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell14.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: stad3-42-xy5_cebp_segm_cell15.tif is a low contrast image\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:137: UserWarning: stad3-42-xy5_dapi_segm_cell15.tif is a low contrast image\n"
     ]
    }
   ],
   "source": [
    "os.chdir(segm_img_dir)\n",
    "\n",
    "df_running_lst = []\n",
    "\n",
    "file_number = 147\n",
    "\n",
    "'''quick checke to make sure that image hasnt already been looked at'''\n",
    "#if file_number in file_numbers_used:\n",
    " #   raise ValueError('file already segmented')\n",
    "    \n",
    "    \n",
    "segm_img_filelist = []\n",
    "for segm_img_filename in os.listdir():\n",
    "    if '.tif' in segm_img_filename:\n",
    "        segm_img_filelist.append(segm_img_filename)\n",
    "segm_img_filelist = [segm_img_filelist[file_number]]   #this is temporary for testing on single image     \n",
    "\n",
    "for segm_img_filename in segm_img_filelist:\n",
    "#for segm_img_filename in temp_lst:\n",
    "    os.chdir(segm_img_dir)\n",
    "    segm_img = io.imread(segm_img_filename) #read in segmented image\n",
    "    \n",
    "    '''the next part is finding the associated fluoresence images'''\n",
    "    subdir = segm_img_filename[:-20] #generate name of subdiretory based on segmented image name\n",
    "    os.chdir(orig_img_dir_base+'\\\\'+subdir) #change to directory with the original images\n",
    "    filename_base = segm_img_filename[:-16] #generate a base filename for the fluorescent images\n",
    "    \n",
    "    dapi_orig_img = io.imread(filename_base+'c1.tif') #read in original dapi image\n",
    "    #dapi_orig_img = np.multiply(dapi_orig_img, segm_img)\n",
    "    #ppar_orig_img = io.imread(filename_base+'c3.tif') #read in original ppar image\n",
    "    cebp_orig_img = io.imread(filename_base+'c4.tif') #read in original cebp image\n",
    "    #cebp_orig_img = np.multiply(cebp_orig_img, segm_img)\n",
    "\n",
    "#ax = plt.imshow(cebp_indy_cell)\n",
    "    cebp_img_dict = {}\n",
    "    dapi_img_dict = {}\n",
    "        \n",
    "    '''lists of parameters to iterate over'''    \n",
    "    param1_lst =  [1, 1.125, 1.325, 1.5, 2, 2.5]\n",
    "    param2_lst = [.005, .00625, .0075, .01, .0125, .015]\n",
    "        \n",
    "    count = 0 #running count for where placing images in subplot \n",
    "    for i in range(len(param1_lst)): #iterater over the firt parameter list\n",
    "        param1 = param1_lst[i]\n",
    "        for j in range(len(param2_lst)): #iterate over the second parameter list\n",
    "            param2 = param2_lst[j]\n",
    "            bw_cebp = cebp_blobs(cebp_orig_img, s2_params = [[param1, param2]]) #run through segmentaiton function\n",
    "            \n",
    "            cebp_img_dict.update({'image#'+str(count) : bw_cebp})\n",
    "            \n",
    "            param1_dapi = 1.75 * param1\n",
    "            param2_dapi = 1.75 * param2\n",
    "            \n",
    "            bw_dapi = cebp_blobs(dapi_orig_img, s2_params = [[param1_dapi, param2_dapi]])\n",
    "            \n",
    "            dapi_img_dict.update({'image#'+str(count) : bw_dapi})\n",
    "            #img_dict.update({'param1:'+str(param1)+' param2:'+str(param2) : bw_})\n",
    "            #axes[count].imshow(cebp_indy_cell)\n",
    "            #axes[count].axis(False)\n",
    "            count+=1\n",
    "           \n",
    "            #axes[count].imshow(bw_[minr:maxr, minc:maxc])\n",
    "    \n",
    "            \n",
    "            #axes[count].axis('off')\n",
    "            #axes[count].title.set_text(str(count))\n",
    "            #axes[count].title.set_text('image# : '+str(count))\n",
    "    \n",
    "            #count+=1\n",
    "            \n",
    "        \n",
    "    labeled_img = measure.label(segm_img) #label the objects within the image \n",
    "    \n",
    "    for nucleus in np.unique(labeled_img)[1:]:\n",
    "        \n",
    "        nucleus_bool_array = np.array(labeled_img == nucleus).astype('uint16') #generate boolean mask of single cell\n",
    "        minr, minc, maxr, maxc = measure.regionprops(nucleus_bool_array)[0].bbox #determine a bounding box for the image\n",
    "        \n",
    "        '''normalize the image for visualizaiton puposes'''\n",
    "        cebp95 =  cebp_orig_img[minr:maxr, minc:maxc] <= np.quantile(cebp_orig_img[minr:maxr, minc:maxc], .95)\n",
    "        cebp05 =  cebp_orig_img[minr:maxr, minc:maxc] >= np.quantile(cebp_orig_img[minr:maxr, minc:maxc], .05)\n",
    "        cebp_mid = np.logical_and(cebp95, cebp05)\n",
    "        cebp_normer_ = np.multiply(cebp_orig_img[minr:maxr, minc:maxc], cebp_mid)\n",
    "        cebp_normed_ = np.divide(cebp_orig_img[minr:maxr, minc:maxc], np.mean(cebp_normer_))\n",
    "        \n",
    "        \n",
    "        cebp_fig = plt.imshow(cebp_normed_, cmap = 'gray')\n",
    "        \n",
    "        fig1, axes = plt.subplots(len(param1_lst), len(param2_lst)) #subplot for segm images\n",
    "        axes = axes.flatten() #flatten axes to make iteration easier\n",
    "        plt.rcParams['font.size'] = 8 #make text smaller   \n",
    "        \n",
    "        \n",
    "        '''generate a subplot of segmented cebp images and choose the best one'''\n",
    "        count = 0 #running count for where placing images in subplot \n",
    "        for image in cebp_img_dict.keys():\n",
    "            segm_img_ = cebp_img_dict[image]\n",
    "            axes[count].imshow(segm_img_[minr:maxr, minc:maxc])\n",
    "            #axes[count].imshow(np.multiply(cebp_orig_img, segm_img_)[minr:maxr, minc:maxc], cmap = 'Reds', alpha = .3)\n",
    "            axes[count].axis('off')\n",
    "            axes[count].title.set_text(image)\n",
    "            count+=1\n",
    "        picked_cebp_img_number = easygui.enterbox('which image?')\n",
    "        plt.close('all')\n",
    "        picked_cebp_img = cebp_img_dict['image#'+str(picked_cebp_img_number)]\n",
    "        \n",
    "        cebp_segm = np.multiply(nucleus_bool_array, picked_cebp_img).astype('uint16')\n",
    "        os.chdir(cebp_segm_dir)\n",
    "        io.imsave(segm_img_filename[:-16]+'_cebp_segm_cell'+str(nucleus)+'.tif', cebp_segm)\n",
    "        \n",
    "        cebp_used_lst.append(picked_cebp_img_number)\n",
    "        '''dapi'''\n",
    "        dapi95 =  dapi_orig_img[minr:maxr, minc:maxc] <= np.quantile(dapi_orig_img[minr:maxr, minc:maxc], .95)\n",
    "        dapi05 =  dapi_orig_img[minr:maxr, minc:maxc] >= np.quantile(dapi_orig_img[minr:maxr, minc:maxc], .05)\n",
    "        dapi_mid = np.logical_and(dapi95, dapi05)\n",
    "        dapi_normer_ = np.multiply(dapi_orig_img[minr:maxr, minc:maxc], dapi_mid)\n",
    "        dapi_normed_ = np.divide(dapi_orig_img[minr:maxr, minc:maxc], np.mean(dapi_normer_))\n",
    "        dapi_fig = plt.imshow(dapi_normed_, cmap = 'gray')\n",
    "        \n",
    "        fig1, axes = plt.subplots(len(param1_lst), len(param2_lst)) #subplot for segm images\n",
    "        axes = axes.flatten() #flatten axes to make iteration easier\n",
    "        plt.rcParams['font.size'] = 8 #make text smaller \n",
    "        \n",
    "        count = 0 #running count for where placing images in subplot \n",
    "        for image in dapi_img_dict.keys():\n",
    "            segm_img_ = dapi_img_dict[image]\n",
    "            axes[count].imshow(segm_img_[minr:maxr, minc:maxc])\n",
    "            axes[count].axis('off')\n",
    "            axes[count].title.set_text(image)\n",
    "            count+=1\n",
    "        picked_dapi_img_number = easygui.enterbox('which image?')\n",
    "        plt.close('all')\n",
    "        picked_dapi_img = dapi_img_dict['image#'+str(picked_dapi_img_number)]\n",
    "        \n",
    "        dapi_segm = np.multiply(nucleus_bool_array, picked_dapi_img).astype('uint16')\n",
    "        os.chdir(dapi_segm_dir)\n",
    "        io.imsave(segm_img_filename[:-16]+'_dapi_segm_cell'+str(nucleus)+'.tif', dapi_segm)\n",
    "        \n",
    "        dapi_used_lst.append(picked_dapi_img_number)\n",
    "        \n",
    "os.chdir(r'Z:\\TAD\\200428_adipogenesis_timecourses_revisited\\190718_3t3l1_time_course_r5')\n",
    "used_df = pd.DataFrame({'cebp_used_number' : cebp_used_lst,\n",
    "                      'dapi_used_number' : dapi_used_lst})\n",
    "used_df.to_csv('used_img_numbers_v2_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nucleus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5818.5999999999985"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(cebp_orig_img[minr:maxr, minc:maxc], .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''purge cebp segmented directory of blank images'''\n",
    "\n",
    "os.chdir(cebp_segm_dir)\n",
    "tiff_lst = []\n",
    "for i in os.listdir():\n",
    "    if 'tif' in i:\n",
    "        tiff_lst.append(i)\n",
    "\n",
    "        \n",
    "out_lst = []\n",
    "for i in tiff_lst:\n",
    "    img_ = io.imread(i)\n",
    "    if np.sum(img_) == 0:\n",
    "        #os.remove(i)\n",
    "        out_lst.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stad3-26-xy5_cebp_segm_cell4.tif',\n",
       " 'stad3-42-xy3_cebp_segm_cell1.tif',\n",
       " 'stad3-42-xy4_cebp_segm_cell11.tif',\n",
       " 'stad3-42-xy4_cebp_segm_cell14.tif',\n",
       " 'stad3-42-xy4_cebp_segm_cell15.tif']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in out_lst:\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-3.0': 21,\n",
       " '-1.0': 30,\n",
       " '0.0': 45,\n",
       " '0.083': 34,\n",
       " '0.167': 34,\n",
       " '0.25': 41,\n",
       " '0.33': 37,\n",
       " '1.0': 27,\n",
       " '2.0': 33,\n",
       " '3.0': 32,\n",
       " '4.0': 29,\n",
       " '6.0': 36}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''figure out how many segmented images for each time point'''\n",
    "os.chdir(segm_img_dir)\n",
    "\n",
    "img_lst_temp = []\n",
    "\n",
    "for filename in os.listdir():\n",
    "    if '.tif' in filename:\n",
    "        img_lst_temp.append(filename[:-20])\n",
    "img_lst_4_times = np.unique(img_lst_temp)\n",
    "\n",
    "\n",
    "times_4_dict = [-3, -1, 0, 0, .083, .083, .167, .167, .25, .25, .33, .33, 1, 1, 2, 2, 3, 3, 4, 4, 6, 6, -1] #list of times associated with images\n",
    "times_dict = {}\n",
    "\n",
    "for i in range(len(img_lst_4_times)):\n",
    "    img_name = img_lst_4_times[i]\n",
    "    time = times_4_dict[i]\n",
    "    \n",
    "    times_dict.update({img_name : time})\n",
    "\n",
    "\n",
    "os.chdir(cebp_segm_dir)\n",
    "tiff_lst = []\n",
    "for i in os.listdir():\n",
    "    if 'tif' in i:\n",
    "        tiff_lst.append(i)\n",
    "\n",
    "        \n",
    "time_img_count_lst = []\n",
    "for i in tiff_lst: \n",
    "    time_img_count_lst.append(times_dict[i[:8]])\n",
    "\n",
    "count_lst = []\n",
    "for i in np.unique(time_img_count_lst):\n",
    "    count_lst.append(np.sum(np.array(time_img_count_lst == i)))\n",
    "\n",
    "time_count_dict = {}\n",
    "for i in range(len(count_lst)):\n",
    "    time_count_dict.update({str(np.unique(time_img_count_lst)[i]) : count_lst[i]})\n",
    "time_count_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-3.0': 23,\n",
       " '-1.0': 31,\n",
       " '0.0': 46,\n",
       " '0.083': 35,\n",
       " '0.167': 22,\n",
       " '0.25': 27,\n",
       " '0.33': 25,\n",
       " '1.0': 20,\n",
       " '2.0': 27,\n",
       " '3.0': 33,\n",
       " '4.0': 24,\n",
       " '6.0': 18}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(count_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labeled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axes = plt.subplots(len(param1_lst), len(param2_lst)) #subplot for segm images\n",
    "axes = axes.flatten() #flatten axes to make iteration easier\n",
    "plt.rcParams['font.size'] = 8 #make text smaller   \n",
    "\n",
    "count = 0 #running count for where placing images in subplot \n",
    "for image in img_dict.keys():\n",
    "    segm_img = img_dict[image]\n",
    "    axes[count].imshow(segm_img[minr:maxr, minc:maxc])\n",
    "    axes[count].axis('off')\n",
    "    axes[count].title.set_text(image)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''the next part will be iterateing over the individual objects in the segmented image and getting info regarding dapi, cebpb and pparg'''\n",
    "for nucleus in [np.unique(labeled_img)[4]]:\n",
    "    nucleus_bool_array = np.array(labeled_img == nucleus).astype('uint16') #generate boolean mask of single cell\n",
    "      \n",
    "    cebp_indy_cell = np.multiply(nucleus_bool_array, cebp_orig_img)\n",
    "      \n",
    "      \n",
    "    '''this is iterating over a bunch of parameters to find the best one for CEBPb segmentaiton'''\n",
    "      #ax = plt.imshow(cebp_indy_cell)\n",
    "    img_dict = {}\n",
    "      \n",
    "      \n",
    "    minr, minc, maxr, maxc = measure.regionprops(nucleus_bool_array)[0].bbox #determine a bounding box for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 495, 456, 763)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure.regionprops(nucleus_bool_array)[0].bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = measure.regionprops(labeled_img)[0].bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.imshow(cebp_orig_img[minr:maxr, minc:maxc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in c:\\users\\legantlab\\anaconda3\\lib\\site-packages (0.48.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\legantlab\\anaconda3\\lib\\site-packages (from numba) (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\legantlab\\anaconda3\\lib\\site-packages (from numba) (1.18.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\legantlab\\anaconda3\\lib\\site-packages (from numba) (45.2.0.post20200210)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this is function adapted taken from:\n",
    "https://github.com/AllenInstitute/aics-segmentation/blob/master/aicssegmentation/core/seg_dot.py'''\n",
    "@jit\n",
    "def dot_2d(struct_img, s2_param):\n",
    "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
    "    for fid in range(len(s2_param)):\n",
    "        log_sigma = s2_param[fid][0]\n",
    "        responce = np.zeros_like(struct_img)\n",
    "        responce = -1*(log_sigma**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma)\n",
    "        bw = np.logical_or(bw, responce>s2_param[fid][1])\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this is function to find cebp beta blobs'''\n",
    "@jit\n",
    "def cebp_blobs(img_, image_scaling_parms = [.5, 10], gaussian_sigma = 1, s2_params = [[1.0, .03]]):\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    intensity_scaling_param = image_scaling_parms\n",
    "    gaussian_smoothing_sigma = gaussian_sigma\n",
    "    ################################\n",
    "    # intensity normalization\n",
    "    struct_img = np.divide(img_, np.max(img_))\n",
    "    \n",
    "    # smoothing with gaussian filter\n",
    "    structure_img_smooth = gaussian(struct_img, sigma=gaussian_smoothing_sigma)\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    s2_param = s2_params\n",
    "    ################################\n",
    "    \n",
    "    bw = dot_2d(structure_img_smooth, s2_param)\n",
    "        #remove small objects\n",
    "    jnk = remove_small_objects(bw)\n",
    "    \n",
    "    return(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def make_cebp_dapi_img_dict(cebp_img_, dapi_img_, param_lst1_f, param_lst2_f):\n",
    "    cebp_segm_img_dict = {}\n",
    "    dapi_segm_img_dict = {}\n",
    "    '''lists of parameters to iterate over'''\n",
    "    param1_lst_ = param_lst1_f\n",
    "    param2_lst_ = param_lst2_f\n",
    "        \n",
    "    count = 0 #running count for where placing images in subplot \n",
    "    for i in range(len(param1_lst_)): #iterater over the firt parameter list\n",
    "        param1 = param1_lst_[i]\n",
    "        for j in range(len(param2_lst_)): #iterate over the second parameter list\n",
    "            param2 = param2_lst_[j]\n",
    "            bw_cebp = cebp_blobs(cebp_img_, s2_params = [[param1, param2]]) #run through segmentaiton function\n",
    "            \n",
    "            cebp_segm_img_dict.update({'image#'+str(count) : bw_cebp})\n",
    "            \n",
    "            param1_dapi = 1.5 * param1\n",
    "            param2_dapi = 1.5 * param2\n",
    "            \n",
    "            bw_dapi = cebp_blobs(dapi_img_, s2_params = [[param1_dapi, param2_dapi]])\n",
    "            \n",
    "            dapi_segm_img_dict.update({'image#'+str(count) : bw_dapi})\n",
    "            #img_dict.update({'param1:'+str(param1)+' param2:'+str(param2) : bw_})\n",
    "            #axes[count].imshow(cebp_indy_cell)\n",
    "            #axes[count].axis(False)\n",
    "            count+=1\n",
    "           \n",
    "            #axes[count].imshow(bw_[minr:maxr, minc:maxc])\n",
    "    \n",
    "            \n",
    "            #axes[count].axis('off')\n",
    "            #axes[count].title.set_text(str(count))\n",
    "            #axes[count].title.set_text('image# : '+str(count))\n",
    "    \n",
    "            #count+=1\n",
    "    return(cebp_segm_img_dict, dapi_segm_img_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-1346bee32501>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"make_cebp_dapi_img_dict\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mInvalid use of type(CPUDispatcher(<function cebp_blobs at 0x0000025CE7419318>)) with parameters (array(uint16, 2d, C), s2_params=list(list(float64)))\n",
      " * parameterized\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: resolving callee type: type(CPUDispatcher(<function cebp_blobs at 0x0000025CE7419318>))\u001b[0m\n",
      "\u001b[0m\u001b[1m[2] During: typing of call at <ipython-input-8-1346bee32501> (14)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-1346bee32501>\", line 14:\u001b[0m\n",
      "\u001b[1mdef make_cebp_dapi_img_dict(cebp_img_, dapi_img_, param_lst1_f, param_lst2_f):\n",
      "    <source elided>\n",
      "            param2 = param2_lst_[j]\n",
      "\u001b[1m            bw_cebp = cebp_blobs(cebp_img_, s2_params = [[param1, param2]]) #run through segmentaiton function\n",
      "\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "<ipython-input-8-1346bee32501>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"make_cebp_dapi_img_dict\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-1346bee32501>\", line 10:\u001b[0m\n",
      "\u001b[1mdef make_cebp_dapi_img_dict(cebp_img_, dapi_img_, param_lst1_f, param_lst2_f):\n",
      "    <source elided>\n",
      "    count = 0 #running count for where placing images in subplot \n",
      "\u001b[1m    for i in range(len(param1_lst_)): #iterater over the firt parameter list\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"make_cebp_dapi_img_dict\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-1346bee32501>\", line 3:\u001b[0m\n",
      "\u001b[1mdef make_cebp_dapi_img_dict(cebp_img_, dapi_img_, param_lst1_f, param_lst2_f):\n",
      "\u001b[1m    cebp_segm_img_dict = {}\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-1346bee32501>\", line 3:\u001b[0m\n",
      "\u001b[1mdef make_cebp_dapi_img_dict(cebp_img_, dapi_img_, param_lst1_f, param_lst2_f):\n",
      "\u001b[1m    cebp_segm_img_dict = {}\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-8-1346bee32501>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"make_cebp_dapi_img_dict\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-8-1346bee32501> (10)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-1346bee32501>\", line 10:\u001b[0m\n",
      "\u001b[1mdef make_cebp_dapi_img_dict(cebp_img_, dapi_img_, param_lst1_f, param_lst2_f):\n",
      "    <source elided>\n",
      "    count = 0 #running count for where placing images in subplot \n",
      "\u001b[1m    for i in range(len(param1_lst_)): #iterater over the firt parameter list\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"make_cebp_dapi_img_dict\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-1346bee32501>\", line 10:\u001b[0m\n",
      "\u001b[1mdef make_cebp_dapi_img_dict(cebp_img_, dapi_img_, param_lst1_f, param_lst2_f):\n",
      "    <source elided>\n",
      "    count = 0 #running count for where placing images in subplot \n",
      "\u001b[1m    for i in range(len(param1_lst_)): #iterater over the firt parameter list\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-1346bee32501>\", line 10:\u001b[0m\n",
      "\u001b[1mdef make_cebp_dapi_img_dict(cebp_img_, dapi_img_, param_lst1_f, param_lst2_f):\n",
      "    <source elided>\n",
      "    count = 0 #running count for where placing images in subplot \n",
      "\u001b[1m    for i in range(len(param1_lst_)): #iterater over the firt parameter list\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-5-1ec24c744104>:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"cebp_blobs\" failed type inference due to: \u001b[1mUntyped global name 'gaussian':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-1ec24c744104>\", line 13:\u001b[0m\n",
      "\u001b[1mdef cebp_blobs(img_, image_scaling_parms = [.5, 10], gaussian_sigma = 1, s2_params = [[1.0, .03]]):\n",
      "    <source elided>\n",
      "    # smoothing with gaussian filter\n",
      "\u001b[1m    structure_img_smooth = gaussian(struct_img, sigma=gaussian_smoothing_sigma)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"cebp_blobs\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-1ec24c744104>\", line 3:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef cebp_blobs(img_, image_scaling_parms = [.5, 10], gaussian_sigma = 1, s2_params = [[1.0, .03]]):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-1ec24c744104>\", line 3:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef cebp_blobs(img_, image_scaling_parms = [.5, 10], gaussian_sigma = 1, s2_params = [[1.0, .03]]):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-4-fe8c479a5933>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"dot_2d\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mInvalid use of Function(<built-in function zeros>) with argument(s) of type(s): (UniTuple(int64 x 2), dtype=Function(<class 'bool'>))\n",
      " * parameterized\n",
      "\u001b[1mIn definition 0:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 1:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mThis error is usually caused by passing an argument of a type that is unsupported by the named function.\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: resolving callee type: Function(<built-in function zeros>)\u001b[0m\n",
      "\u001b[0m\u001b[1m[2] During: typing of call at <ipython-input-4-fe8c479a5933> (5)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 5:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "\u001b[1m    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "<ipython-input-4-fe8c479a5933>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"dot_2d\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 6:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[1m    for fid in range(len(s2_param)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"dot_2d\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 5:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "\u001b[1m    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 5:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "\u001b[1m    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-4-fe8c479a5933>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"dot_2d\" failed type inference due to: \u001b[1m\u001b[1mUnknown attribute 'gaussian_laplace' of type Module(<module 'scipy.ndimage.filters' from 'C:\\\\Users\\\\LegantLab\\\\anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\ndimage\\\\filters.py'>)\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 9:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "        responce = np.zeros_like(struct_img)\n",
      "\u001b[1m        responce = -1*(log_sigma**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of get attribute at <ipython-input-4-fe8c479a5933> (9)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 9:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "        responce = np.zeros_like(struct_img)\n",
      "\u001b[1m        responce = -1*(log_sigma**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"dot_2d\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 6:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[1m    for fid in range(len(s2_param)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 6:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[1m    for fid in range(len(s2_param)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-5-1ec24c744104>:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"cebp_blobs\" failed type inference due to: \u001b[1mUntyped global name 'gaussian':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-1ec24c744104>\", line 13:\u001b[0m\n",
      "\u001b[1mdef cebp_blobs(img_, image_scaling_parms = [.5, 10], gaussian_sigma = 1, s2_params = [[1.0, .03]]):\n",
      "    <source elided>\n",
      "    # smoothing with gaussian filter\n",
      "\u001b[1m    structure_img_smooth = gaussian(struct_img, sigma=gaussian_smoothing_sigma)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"cebp_blobs\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-1ec24c744104>\", line 3:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef cebp_blobs(img_, image_scaling_parms = [.5, 10], gaussian_sigma = 1, s2_params = [[1.0, .03]]):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-1ec24c744104>\", line 3:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef cebp_blobs(img_, image_scaling_parms = [.5, 10], gaussian_sigma = 1, s2_params = [[1.0, .03]]):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-4-fe8c479a5933>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"dot_2d\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mInvalid use of Function(<built-in function zeros>) with argument(s) of type(s): (UniTuple(int64 x 2), dtype=Function(<class 'bool'>))\n",
      " * parameterized\n",
      "\u001b[1mIn definition 0:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 1:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mThis error is usually caused by passing an argument of a type that is unsupported by the named function.\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: resolving callee type: Function(<built-in function zeros>)\u001b[0m\n",
      "\u001b[0m\u001b[1m[2] During: typing of call at <ipython-input-4-fe8c479a5933> (5)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 5:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "\u001b[1m    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "<ipython-input-4-fe8c479a5933>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"dot_2d\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 6:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[1m    for fid in range(len(s2_param)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"dot_2d\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 5:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "\u001b[1m    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 5:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "\u001b[1m    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-4-fe8c479a5933>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"dot_2d\" failed type inference due to: \u001b[1m\u001b[1mUnknown attribute 'gaussian_laplace' of type Module(<module 'scipy.ndimage.filters' from 'C:\\\\Users\\\\LegantLab\\\\anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\ndimage\\\\filters.py'>)\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 9:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "        responce = np.zeros_like(struct_img)\n",
      "\u001b[1m        responce = -1*(log_sigma**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of get attribute at <ipython-input-4-fe8c479a5933> (9)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 9:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "        responce = np.zeros_like(struct_img)\n",
      "\u001b[1m        responce = -1*(log_sigma**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"dot_2d\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 6:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[1m    for fid in range(len(s2_param)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "C:\\Users\\LegantLab\\anaconda3\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-fe8c479a5933>\", line 6:\u001b[0m\n",
      "\u001b[1mdef dot_2d(struct_img, s2_param):\n",
      "    <source elided>\n",
      "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
      "\u001b[1m    for fid in range(len(s2_param)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image#None'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f9a59b5a698a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mpicked_cebp_img_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0measygui\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menterbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'which image?'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mpicked_cebp_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcebp_img_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image#'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpicked_cebp_img_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mcebp_segm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnucleus_bool_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpicked_cebp_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image#None'"
     ]
    }
   ],
   "source": [
    "os.chdir(segm_img_dimake_cebp_dapi_img_dictnning_lst = []\n",
    "\n",
    "\n",
    "#segm_img_filelist = []\n",
    "#for segm_img_filename in os.listdir():\n",
    "#    if '.tif' in segm_img_filename:\n",
    "#        segm_img_filelist.append(segm_img_filename)\n",
    "segm_img_filelist = ['stad3-30-xy5segm_parsed.tiff', 'stad3-30-xy6segm_parsed.tiff']   #this is temporary for testing on single image     \n",
    "\n",
    "for segm_img_filename in segm_img_filelist:\n",
    "#for segm_img_filename in temp_lst:\n",
    "    os.chdir(segm_img_dir)\n",
    "    segm_img = io.imread(segm_img_filename) #read in segmented image\n",
    "    \n",
    "    '''the next part is finding the associated fluoresence images'''\n",
    "    subdir = segm_img_filename[:-20] #generate name of subdiretory based on segmented image name\n",
    "    os.chdir(orig_img_dir_base+'\\\\'+subdir) #change to directory with the original images\n",
    "    filename_base = segm_img_filename[:-16] #generate a base filename for the fluorescent images\n",
    "    \n",
    "    dapi_orig_img = io.imread(filename_base+'c1.tif') #read in original dapi image\n",
    "    #ppar_orig_img = io.imread(filename_base+'c3.tif') #read in original ppar image\n",
    "    cebp_orig_img = io.imread(filename_base+'c4.tif') #read in original cebp image\n",
    "\n",
    "\n",
    "    param1_lst =  [1, 2, 2.5, 3.0, 3.5, 4, 4.5]\n",
    "    param2_lst = [.005, .01, .015, .02, .025, .03]\n",
    "    cebp_img_dict, dapi_img_dict = make_cebp_dapi_img_dict(cebp_orig_img, dapi_orig_img, param1_lst, param2_lst)\n",
    "        \n",
    "   \n",
    "            \n",
    "        \n",
    "    labeled_img = measure.label(segm_img) #label the objects within the image \n",
    "    \n",
    "    for nucleus in np.unique(labeled_img)[3:5]:\n",
    "        \n",
    "        nucleus_bool_array = np.array(labeled_img == nucleus).astype('uint16') #generate boolean mask of single cell\n",
    "        minr, minc, maxr, maxc = measure.regionprops(nucleus_bool_array)[0].bbox #determine a bounding box for the image\n",
    "    \n",
    "        cebp_fig = plt.imshow(cebp_orig_img[minr:maxr, minc:maxc])\n",
    "        \n",
    "        fig1, axes = plt.subplots(len(param1_lst), len(param2_lst)) #subplot for segm images\n",
    "        axes = axes.flatten() #flatten axes to make iteration easier\n",
    "        plt.rcParams['font.size'] = 8 #make text smaller   \n",
    "        \n",
    "        \n",
    "        '''generate a subplot of segmented cebp images and choose the best one'''\n",
    "        count = 0 #running count for where placing images in subplot \n",
    "        for image in cebp_img_dict.keys():\n",
    "            segm_img_ = cebp_img_dict[image]\n",
    "            axes[count].imshow(segm_img_[minr:maxr, minc:maxc])\n",
    "            axes[count].axis('off')\n",
    "            axes[count].title.set_text(image)\n",
    "            count+=1\n",
    "        picked_cebp_img_number = easygui.enterbox('which image?')\n",
    "        plt.close('all')\n",
    "        picked_cebp_img = cebp_img_dict['image#'+str(picked_cebp_img_number)]\n",
    "        \n",
    "        cebp_segm = np.multiply(nucleus_bool_array, picked_cebp_img).astype('uint16')\n",
    "        os.chdir(cebp_segm_dir)\n",
    "        io.imsave(segm_img_filename[:-16]+'_cebp_segm_cell'+str(nucleus)+'.tif', cebp_segm)\n",
    "        \n",
    "        \n",
    "        '''dapi'''\n",
    "        dapi_fig = plt.imshow(dapi_orig_img[minr:maxr, minc:maxc])\n",
    "        \n",
    "        fig1, axes = plt.subplots(len(param1_lst), len(param2_lst)) #subplot for segm images\n",
    "        axes = axes.flatten() #flatten axes to make iteration easier\n",
    "        plt.rcParams['font.size'] = 8 #make text smaller \n",
    "        \n",
    "        count = 0 #running count for where placing images in subplot \n",
    "        for image in dapi_img_dict.keys():\n",
    "            segm_img_ = dapi_img_dict[image]\n",
    "            axes[count].imshow(segm_img_[minr:maxr, minc:maxc])\n",
    "            axes[count].axis('off')\n",
    "            axes[count].title.set_text(image)\n",
    "            count+=1\n",
    "        picked_dapi_img_number = easygui.enterbox('which image?')\n",
    "        plt.close('all')\n",
    "        picked_dapi_img = dapi_img_dict['image#'+str(picked_dapi_img_number)]\n",
    "        \n",
    "        dapi_segm = np.multiply(nucleus_bool_array, picked_dapi_img).astype('uint16')\n",
    "        os.chdir(dapi_segm_dir)\n",
    "        io.imsave(segm_img_filename[:-16]+'_dapi_segm_cell'+str(nucleus)+'.tif', dapi_segm)\n",
    "        \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for timing'''\n",
    "os.chdir(segm_img_dir)\n",
    "\n",
    "df_running_lst = []\n",
    "\n",
    "\n",
    "#segm_img_filelist = []\n",
    "#for segm_img_filename in os.listdir():\n",
    "#    if '.tif' in segm_img_filename:\n",
    "#        segm_img_filelist.append(segm_img_filename)\n",
    "segm_img_filelist = ['stad3-30-xy5segm_parsed.tiff', 'stad3-30-xy6segm_parsed.tiff']   #this is temporary for testing on single image     \n",
    "\n",
    "for segm_img_filename in segm_img_filelist:\n",
    "#for segm_img_filename in temp_lst:\n",
    "    os.chdir(segm_img_dir)\n",
    "    segm_img = io.imread(segm_img_filename) #read in segmented image\n",
    "    \n",
    "    '''the next part is finding the associated fluoresence images'''\n",
    "    subdir = segm_img_filename[:-20] #generate name of subdiretory based on segmented image name\n",
    "    os.chdir(orig_img_dir_base+'\\\\'+subdir) #change to directory with the original images\n",
    "    filename_base = segm_img_filename[:-16] #generate a base filename for the fluorescent images\n",
    "    \n",
    "    dapi_orig_img = io.imread(filename_base+'c1.tif') #read in original dapi image\n",
    "    #ppar_orig_img = io.imread(filename_base+'c3.tif') #read in original ppar image\n",
    "    cebp_orig_img = io.imread(filename_base+'c4.tif') #read in original cebp image\n",
    "\n",
    "\n",
    "#ax = plt.imshow(cebp_indy_cell)\n",
    "    cebp_img_dict = {}\n",
    "    dapi_img_dict = {}\n",
    "        \n",
    "    '''lists of parameters to iterate over'''    \n",
    "    param1_lst =  [1, 2, 2.5, 3.0, 3.5, 4, 4.5]\n",
    "    param2_lst = [.005, .01, .015, .02, .025, .03]\n",
    "        \n",
    "    count = 0 #running count for where placing images in subplot \n",
    "    for i in range(len(param1_lst)): #iterater over the firt parameter list\n",
    "        param1 = param1_lst[i]\n",
    "        for j in range(len(param2_lst)): #iterate over the second parameter list\n",
    "            param2 = param2_lst[j]\n",
    "            bw_cebp = cebp_blobs(cebp_orig_img, s2_params = [[param1, param2]]) #run through segmentaiton function\n",
    "            \n",
    "            cebp_img_dict.update({'image#'+str(count) : bw_cebp})\n",
    "            \n",
    "            param1_dapi = 1.5 * param1\n",
    "            param2_dapi = 1.5 * param2\n",
    "            \n",
    "            bw_dapi = cebp_blobs(dapi_orig_img, s2_params = [[param1_dapi, param2_dapi]])\n",
    "            \n",
    "            dapi_img_dict.update({'image#'+str(count) : bw_dapi})\n",
    "            #img_dict.update({'param1:'+str(param1)+' param2:'+str(param2) : bw_})\n",
    "            #axes[count].imshow(cebp_indy_cell)\n",
    "            #axes[count].axis(False)\n",
    "            count+=1\n",
    "           \n",
    "            #axes[count].imshow(bw_[minr:maxr, minc:maxc])\n",
    "    \n",
    "            \n",
    "            #axes[count].axis('off')\n",
    "            #axes[count].title.set_text(str(count))\n",
    "            #axes[count].title.set_text('image# : '+str(count))\n",
    "    \n",
    "            #count+=1\n",
    "            \n",
    "        \n",
    "    labeled_img = measure.label(segm_img) #label the objects within the image \n",
    "    \n",
    "    for nucleus in np.unique(labeled_img)[3:5]:\n",
    "        \n",
    "        nucleus_bool_array = np.array(labeled_img == nucleus).astype('uint16') #generate boolean mask of single cell\n",
    "        minr, minc, maxr, maxc = measure.regionprops(nucleus_bool_array)[0].bbox #determine a bounding box for the image\n",
    "    \n",
    "        cebp_fig = plt.imshow(cebp_orig_img[minr:maxr, minc:maxc])\n",
    "        \n",
    "        fig1, axes = plt.subplots(len(param1_lst), len(param2_lst)) #subplot for segm images\n",
    "        axes = axes.flatten() #flatten axes to make iteration easier\n",
    "        plt.rcParams['font.size'] = 8 #make text smaller   \n",
    "        \n",
    "        \n",
    "        '''generate a subplot of segmented cebp images and choose the best one'''\n",
    "        count = 0 #running count for where placing images in subplot \n",
    "        for image in cebp_img_dict.keys():\n",
    "            segm_img_ = cebp_img_dict[image]\n",
    "            axes[count].imshow(segm_img_[minr:maxr, minc:maxc])\n",
    "            axes[count].axis('off')\n",
    "            axes[count].title.set_text(image)\n",
    "            count+=1\n",
    "        picked_cebp_img_number = easygui.enterbox('which image?')\n",
    "        plt.close('all')\n",
    "        picked_cebp_img = cebp_img_dict['image#'+str(picked_cebp_img_number)]\n",
    "        \n",
    "        cebp_segm = np.multiply(nucleus_bool_array, picked_cebp_img).astype('uint16')\n",
    "        os.chdir(cebp_segm_dir)\n",
    "        io.imsave(segm_img_filename[:-16]+'_cebp_segm_cell'+str(nucleus)+'.tif', cebp_segm)\n",
    "        \n",
    "        \n",
    "        '''dapi'''\n",
    "        dapi_fig = plt.imshow(dapi_orig_img[minr:maxr, minc:maxc])\n",
    "        \n",
    "        fig1, axes = plt.subplots(len(param1_lst), len(param2_lst)) #subplot for segm images\n",
    "        axes = axes.flatten() #flatten axes to make iteration easier\n",
    "        plt.rcParams['font.size'] = 8 #make text smaller \n",
    "        \n",
    "        count = 0 #running count for where placing images in subplot \n",
    "        for image in dapi_img_dict.keys():\n",
    "            segm_img_ = dapi_img_dict[image]\n",
    "            axes[count].imshow(segm_img_[minr:maxr, minc:maxc])\n",
    "            axes[count].axis('off')\n",
    "            axes[count].title.set_text(image)\n",
    "            count+=1\n",
    "        picked_dapi_img_number = easygui.enterbox('which image?')\n",
    "        plt.close('all')\n",
    "        picked_dapi_img = dapi_img_dict['image#'+str(picked_dapi_img_number)]\n",
    "        \n",
    "        dapi_segm = np.multiply(nucleus_bool_array, picked_dapi_img).astype('uint16')\n",
    "        os.chdir(dapi_segm_dir)\n",
    "        io.imsave(segm_img_filename[:-16]+'_dapi_segm_cell'+str(nucleus)+'.tif', dapi_segm)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.9707567691803\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cebp_img_dict = {}\n",
    "dapi_img_dict = {}\n",
    "        \n",
    "'''lists of parameters to iterate over'''    \n",
    "param1_lst =  [1, 2, 2.5, 3.0, 3.5, 4, 4.5]\n",
    "param2_lst = [.005, .01, .015, .02, .025, .03]\n",
    "    \n",
    "count = 0 #running count for where placing images in subplot \n",
    "for i in range(len(param1_lst)): #iterater over the firt parameter list\n",
    "    param1 = param1_lst[i]\n",
    "    for j in range(len(param2_lst)): #iterate over the second parameter list\n",
    "        param2 = param2_lst[j]\n",
    "        bw_cebp = cebp_blobs(cebp_orig_img, s2_params = [[param1, param2]]) #run through segmentaiton function\n",
    "        \n",
    "        cebp_img_dict.update({'image#'+str(count) : bw_cebp})\n",
    "        \n",
    "        param1_dapi = 1.5 * param1\n",
    "        param2_dapi = 1.5 * param2\n",
    "        \n",
    "        bw_dapi = cebp_blobs(dapi_orig_img, s2_params = [[param1_dapi, param2_dapi]])\n",
    "        \n",
    "        dapi_img_dict.update({'image#'+str(count) : bw_dapi})\n",
    "        #img_dict.update({'param1:'+str(param1)+' param2:'+str(param2) : bw_})\n",
    "        #axes[count].imshow(cebp_indy_cell)\n",
    "        #axes[count].axis(False)\n",
    "        count+=1\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.52328610420227\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cebp_img_dict, dapi_img_dict = make_cebp_dapi_img_dict(cebp_orig_img, dapi_orig_img, param1_lst, param2_lst)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this is function adapted taken from:\n",
    "https://github.com/AllenInstitute/aics-segmentation/blob/master/aicssegmentation/core/seg_dot.py'''\n",
    "\n",
    "def dot_2d(struct_img, s2_param):\n",
    "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
    "    for fid in range(len(s2_param)):\n",
    "        log_sigma = s2_param[fid][0]\n",
    "        responce = np.zeros_like(struct_img)\n",
    "        responce = -1*(log_sigma**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma)\n",
    "        bw = np.logical_or(bw, responce>s2_param[fid][1])\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_2d_lots_return(struct_img, s2_param):\n",
    "    bw = np.zeros(struct_img.shape, dtype=bool)\n",
    "    log_sigma1 = s2_param[0]\n",
    "    responce1 = np.zeros_like(struct_img)\n",
    "    responce1 = -1*(log_sigma1**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma1)\n",
    "    bw1 = np.logical_or(bw, responce1 >s2_param[1])\n",
    "    log_sigma2 = s2_param[1]\n",
    "    responce2 = np.zeros_like(struct_img)\n",
    "    responce2 = -1*(log_sigma2**2)*ndi.filters.gaussian_laplace(struct_img, log_sigma2)\n",
    "        \n",
    "    bw2 = np.logical_or(bw1, responce2 >s2_param[1])\n",
    "    return(responce1, responce2, bw1, bw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'Z:\\TAD\\200428_adipogenesis_timecourses_revisited\\190718_3t3l1_time_course_r5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebp_sample = io.imread('cebp_sample_stad3-40-xy2c4.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_img = np.divide(cebp_sample, np.max(cebp_sample))\n",
    "    \n",
    "    # smoothing with gaussian filter\n",
    "structure_img_smooth = gaussian(struct_img, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebp_responce1, cebp_responce2, cebp_bw1, cebp_bw2 = dot_2d_lots_return(structure_img_smooth, [param1_lst[2], param2_lst[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1_lst =  [1, 2, 2.5, 3.0, 3.5, 4, 4.5]\n",
    "param2_lst = [.005, .01, .015, .02, .025, .03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebp_segm_ = dot_2d(structure_img_smooth, s2_param = [[param1_lst[2], param2_lst[3]]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21012cbfd48>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "ax = ax.flatten()\n",
    "\n",
    "ax[0].imshow(cebp_sample)\n",
    "ax[1].imshow(cebp_segm_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cebp_segm_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2107ba8b888>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "ax = ax.flatten()\n",
    "\n",
    "ax[0].imshow(cebp_responce1)\n",
    "ax[1].imshow(cebp_bw1)\n",
    "#ax[2].imshow(cebp_responce2)\n",
    "#ax[3].imshow(cebp_bw2)\n",
    "\n",
    "#fig1 = plt.imshow(cebp_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:16:24\n"
     ]
    }
   ],
   "source": [
    "print(str(16 - 14) + ':' + str(53 - 37) + ':' + str(42-18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3182957393483709"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "127 / 399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.068897637795276"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(399 / 127) * 2.25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "combine() argument 1 must be datetime.date, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-1e3f3d2ad58b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m37\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdatetime_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdatetime_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdatetime_end\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdatetime_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: combine() argument 1 must be datetime.date, not tuple"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "date = (1, 1, 1)\n",
    "end = datetime.time(19,21,31) \n",
    "start =  datetime.time(14,37,18)\n",
    "datetime_start = datetime.datetime.combine(date,start)\n",
    "datetime_end = datetime.datetime.combine(date,end)\n",
    "datetime_end - datetime_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.736944444444444"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17053 / 60 /60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.21666666666664"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".736944444444444 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0523911691542285"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "399 / 268 * 4.736944444444444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21:40:11 14:37:18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 7:3\n"
     ]
    }
   ],
   "source": [
    "print('time elapsed: ' + str(21 - 14) + ':' + str(40-37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\LegantLab\\Documents\\git\\tad\\Legant_lab\\200428_adipogenesis_timecourses_revisited\\190718_3t3l1_time_course_r5\\img_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_img_numbs1 = pd.read_csv('used_img_numbers.csv')\n",
    "used_img_numbs2 = pd.read_csv('used_img_numbers_d2.csv')\n",
    "\n",
    "used_number_df = pd.concat([used_img_numbs1, used_img_numbs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0', 'cebp_used_number', 'dapi_used_number']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(used_number_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(used_number_df.cebp_used_number, kde = False, bins = np.linspace(0, 40, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for describing cebp segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 220)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cebp_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21026eb1ac8>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(cebp_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coords, x_coords = cebp_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "        44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "        55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "        66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "        77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "        88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "        99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "       110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n",
       "       121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,\n",
       "       132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142.,\n",
       "       143., 144., 145., 146., 147., 148., 149., 150., 151., 152., 153.,\n",
       "       154., 155., 156., 157., 158., 159., 160., 161., 162., 163., 164.,\n",
       "       165., 166., 167., 168., 169., 170., 171., 172., 173., 174., 175.,\n",
       "       176., 177., 178., 179., 180., 181., 182., 183., 184., 185., 186.,\n",
       "       187., 188., 189., 190., 191., 192., 193., 194., 195., 196., 197.,\n",
       "       198., 199., 200., 201., 202., 203., 204., 205., 206., 207., 208.,\n",
       "       209., 210., 211., 212., 213., 214., 215., 216., 217., 218., 219.,\n",
       "       220., 221., 222., 223., 224., 225., 226., 227., 228., 229., 230.,\n",
       "       231., 232.])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, y_coords, y_coords +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coords = []\n",
    "x_coords = []\n",
    "intens = []\n",
    "\n",
    "for y in range(cebp_sample.shape[0]):\n",
    "    for x in range(cebp_sample.shape[1]):\n",
    "        y_coords.append(y)\n",
    "        x_coords.append(cebp_sample.shape[1] - x)\n",
    "        intens.append(cebp_sample[y,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebp_sample_gaussian = gaussian(cebp_sample, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coords = []\n",
    "x_coords = []\n",
    "intens_gauss = []\n",
    "\n",
    "for y in range(cebp_sample.shape[0]):\n",
    "    for x in range(cebp_sample.shape[1]):\n",
    "        y_coords.append(y)\n",
    "        x_coords.append(cebp_sample.shape[1] - x)\n",
    "        intens_gauss.append(cebp_sample_gaussian[y,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-340-05db0bd6dd06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m surf = ax.plot_surface(X, Y, cebp_sample,\n\u001b[1;32m----> 9\u001b[1;33m                        linewidth=0, antialiased=False)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mpl_toolkits\\mplot3d\\axes3d.py\u001b[0m in \u001b[0;36mplot_surface\u001b[1;34m(self, X, Y, Z, norm, vmin, vmax, lightsource, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m         \u001b[1;31m# TODO: Support masked arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1590\u001b[0m         \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;31m# consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m     \u001b[1;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "X = y_lin\n",
    "Y = x_lin\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "surf = ax.plot_surface(X, Y, cebp_sample,\n",
    "                       linewidth=0, antialiased=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(-5, 5, 0.25)\n",
    "Y = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = np.sqrt(X**2 + Y**2)\n",
    "Z = np.sin(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_trisurf(np.array(x_coords), np.array(y_coords), np.array(intens), cmap = 'winter')\n",
    "ax.view_init(45, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_trisurf(np.array(x_coords), np.array(y_coords), np.array(intens_gauss), cmap = 'winter')\n",
    "ax.view_init(45, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2107bb16e48>"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(cebp_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gaussian_laplace() missing 1 required positional argument: 'sigma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-390-26956848673a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcebp_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussian_laplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcebp_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcebp_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: gaussian_laplace() missing 1 required positional argument: 'sigma'"
     ]
    }
   ],
   "source": [
    "cebp_log = gaussian_laplace(cebp_sample, )\n",
    "plt.imshow(cebp_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21073f1f5c8>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import ndimage, misc\n",
    "cebp_sample_normed = np.divide(cebp_sample, np.max(cebp_sample))\n",
    "cebp_log = -1 * ndimage.laplace(cebp_sample_normed)\n",
    "plt.imshow(cebp_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebp_sample_blurred = gaussian(cebp_sample_normed, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21073fa4908>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(cebp_sample_blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2107f7523c8>"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(cebp_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' histogram equalization example script taken from :\n",
    "https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_equalize.html'''\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage import exposure\n",
    "\n",
    "\n",
    "#matplotlib.rcParams['font.size'] = 8\n",
    "\n",
    "\n",
    "def plot_img_and_hist(image, axes, bins= 2 ** 16):\n",
    "    \"\"\"Plot an image along with its histogram and cumulative histogram.\n",
    "\n",
    "    \"\"\"\n",
    "    image = img_as_float(image)\n",
    "    ax_img, ax_hist = axes\n",
    "    ax_cdf = ax_hist.twinx()\n",
    "\n",
    "    # Display image\n",
    "    ax_img.imshow(image, cmap=plt.cm.gray)\n",
    "    ax_img.set_axis_off()\n",
    "\n",
    "    # Display histogram\n",
    "    ax_hist.hist(image.ravel(), bins=bins, histtype='step', color='black')\n",
    "    ax_hist.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))\n",
    "    ax_hist.set_xlabel('Pixel intensity')\n",
    "    ax_hist.set_xlim(0, 1)\n",
    "    ax_hist.set_yticks([])\n",
    "\n",
    "    # Display cumulative distribution\n",
    "    img_cdf, bins = exposure.cumulative_distribution(image, bins)\n",
    "    ax_cdf.plot(bins, img_cdf, 'r')\n",
    "    ax_cdf.set_yticks([])\n",
    "\n",
    "    return ax_img, ax_hist, ax_cdf\n",
    "\n",
    "\n",
    "# Load an example image\n",
    "img = cebp_orig_img[minr:maxr, minc:maxc]\n",
    "\n",
    "# Contrast stretching\n",
    "p2, p98 = np.percentile(img, (1, 99))\n",
    "img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "\n",
    "# Equalization\n",
    "img_eq = exposure.equalize_hist(img)\n",
    "\n",
    "# Adaptive Equalization\n",
    "img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "\n",
    "# Display results\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "axes = np.zeros((2, 4), dtype=np.object)\n",
    "axes[0, 0] = fig.add_subplot(2, 4, 1)\n",
    "for i in range(1, 4):\n",
    "    axes[0, i] = fig.add_subplot(2, 4, 1+i, sharex=axes[0,0], sharey=axes[0,0])\n",
    "for i in range(0, 4):\n",
    "    axes[1, i] = fig.add_subplot(2, 4, 5+i)\n",
    "\n",
    "ax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\n",
    "ax_img.set_title('Low contrast image')\n",
    "\n",
    "y_min, y_max = ax_hist.get_ylim()\n",
    "ax_hist.set_ylabel('Number of pixels')\n",
    "ax_hist.set_yticks(np.linspace(0, y_max, 5))\n",
    "\n",
    "ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_rescale, axes[:, 1])\n",
    "ax_img.set_title('Contrast stretching')\n",
    "\n",
    "ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_eq, axes[:, 2])\n",
    "ax_img.set_title('Histogram equalization')\n",
    "\n",
    "ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_adapteq, axes[:, 3])\n",
    "ax_img.set_title('Adaptive equalization')\n",
    "\n",
    "ax_cdf.set_ylabel('Fraction of total intensity')\n",
    "ax_cdf.set_yticks(np.linspace(0, 1, 5))\n",
    "\n",
    "# prevent overlap of y-axis labels\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
