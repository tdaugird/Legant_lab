{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06-30-20 \n",
    "This is applying segm_obj_classificaiton.ipynb to the vdr-gr data set. \n",
    "\n",
    "\n",
    "06-20-20\n",
    "This is code to annotate nucleus mask images. I have used this pretty extensively for annotating output from Cell Profiler. Included here is is script for:\n",
    "    -Labeling masked image and creating pd dataframe containing size and shape parameters of objects in a labeled objects\n",
    "    -displaying dataframe and associated image for annotation\n",
    "    -creating training dataframes containing annotations\n",
    "    -Training and testing random forest classifier.\n",
    "This is just genreal version that will need to be modified as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up directorys and read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''These will each need to be modified'''\n",
    "\n",
    "orig_img_dir = r'Y:\\TAD\\200610_adipogenesis_timecourse_r10_v2\\gr-rxr-set\\mid_slices' #directory that contains the original not mask image\n",
    "segm_img_dir = r'Y:\\TAD\\200610_adipogenesis_timecourse_r10_v2\\gr-rxr-set\\mid_slice_nucl_segm' #directory that contains the masked image\n",
    "annotated_csv_dir = r'C:\\Users\\LegantLab\\Documents\\git\\tad\\adipogenesis_timcecourses_revisited\\200610_adipogenesis_timecourse_r10_v2\\annotation_csvs' #out put directory for placement of annotated .csv files\n",
    "base_img_name = 'stad434_rois001_fov3_c4' #name of original image without file type\n",
    "segm_img_filename = base_img_name + '_segm.tiff' #name of the segmented image\n",
    "#segm_img_filename = 'stad431_rois001_fov7_c4_segm_.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(orig_img_dir)\n",
    "orig_img = io.imread(base_img_name+'.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up image and corresponding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ae0ab85e08>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(segm_img_dir)\n",
    "segm_img = io.imread(segm_img_filename) #read in the segmented image\n",
    "labeled_img = measure.label(segm_img) #label\n",
    "plt.imshow(labeled_img) #test display of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''make a dataframe of object parameters'''\n",
    "df_whole = pd.DataFrame(measure.regionprops_table(labeled_img, properties = ('label',  'area',  'bbox_area', 'centroid', 'convex_area', \n",
    "                                                       'eccentricity', 'equivalent_diameter',\n",
    "                                                       'extent', 'local_centroid', 'major_axis_length', \n",
    "                                                                   'minor_axis_length', 'perimeter', 'solidity', 'inertia_tensor_eigvals',\n",
    "                                                                            'moments_hu',)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>centroid-1</th>\n",
       "      <th>centroid-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>506</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>903</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1523</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1809</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1339</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>481</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1012</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1690</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>796</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1127</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>539</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2020</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>822</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1897</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1909</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1635</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1360</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1846</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>578</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>989</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>1171</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>918</td>\n",
       "      <td>1459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>486</td>\n",
       "      <td>1483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>1744</td>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1618</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>772</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>124</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>564</td>\n",
       "      <td>1778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>383</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>1210</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>1923</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  centroid-1  centroid-0\n",
       "0       1         506          34\n",
       "1       2         903          71\n",
       "2       3        1523          11\n",
       "3       4        1809          19\n",
       "4       5        2017          56\n",
       "5       6        1339         122\n",
       "6       7         481         194\n",
       "7       8        1012         146\n",
       "11     12        1690         395\n",
       "13     14         796         414\n",
       "16     17        1127         514\n",
       "18     19         539         669\n",
       "19     20        2020         810\n",
       "20     21         822        1008\n",
       "21     22        1897         883\n",
       "22     23        1909         961\n",
       "23     24        1635        1078\n",
       "24     25        1360        1111\n",
       "26     27        1846        1113\n",
       "28     29         578        1264\n",
       "29     30         989        1281\n",
       "30     31        1171        1360\n",
       "32     33          21        1350\n",
       "33     34         918        1459\n",
       "34     35         486        1483\n",
       "35     36        1744        1520\n",
       "36     37        1618        1652\n",
       "37     38         772        1729\n",
       "38     39         124        1752\n",
       "39     40         564        1778\n",
       "40     41         383        1824\n",
       "41     42        1210        1884\n",
       "43     44        1923        1921"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''drop all of the small objects and display dataframe containing label, x and y coordinates'''\n",
    "df_working = df_whole.loc[df_whole.area > 1000]\n",
    "df_working = df_working[['label', 'centroid-1', 'centroid-0']]\n",
    "df_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 5, 9, 11, 14, 13, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2ae0abba608>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plot the labeled image and the centroid of each object on the same plot'''\n",
    "plt.imshow(labeled_img)\n",
    "plt.scatter(df_whole['centroid-1'], df_whole['centroid-0'], color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2ae67a940c8>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plot the original image and the labeled image'''\n",
    "#fig, axes = plt.subplots(2,1)\n",
    "#axes = axes.flatten()\n",
    "\n",
    "#axes[0].imshow(orig_img)\n",
    "#axes[1].imshow(labeled_img)\n",
    "#axes[1].scatter(df_working['centroid-1'], df_working['centroid-0'], color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''anotate the objects to keep'''\n",
    "in_obj_lst = [2, 6, 12, 24, 25, 29, 31, 34, 35, 36, 37, 38, 19, 40, 42, 44] #manually chosen objects to keepo\n",
    "in_obj_lst = np.unique(in_obj_lst) #confirm that things are not duplicated\n",
    "out_obj_lst_concat = np.setdiff1d(np.unique(df_whole.label), in_obj_lst, assume_unique=False) #Take everything that is not chosen and put it into a seperate file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alternativeily can annotate objects to discard'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''alternativeily can annotate objects to discard'''\n",
    "#out_obj_lst_concat = [1, 6, 16]  #manually chosen objects to discard\n",
    "#out_obj_lst_concat = np.unique(out_obj_lst_concat) #confirm that things are not duplicated\n",
    "#in_obj_lst = np.setdiff1d(np.unique(df_whole.label), out_obj_lst_concat, assume_unique=False) #Take everything that is not chosen and put it into a seperate file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = df_whole.loc[df_whole.label.isin(in_obj_lst)] #from the regionprops table, make a seperate df with only the objects to keep\n",
    "df_out = df_whole.loc[df_whole.label.isin(out_obj_lst_concat)] #same as above with objects to not keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''write the dataframes into .csv files'''\n",
    "os.chdir(annotated_csv_dir)\n",
    "df_in.to_csv(base_img_name+'_in_objs.csv')\n",
    "df_out.to_csv(base_img_name+'_out_objs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test new data using old classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and compile all the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First I would like to see if I can use the random forest classifier that I trained before. I think that this might work as the training set images were aquired on same scope so the size parameters should be around the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''read in old annotated data for training'''\n",
    "os.chdir(r'C:\\Users\\LegantLab\\Documents\\git\\tad\\adipogenesis_timcecourses_revisited\\200428_adipogenesis_timecourses_revisited\\190718_3t3l1_time_course_r5\\img_analysis\\annotated_csvs_pythong')\n",
    "df_train_orig = pd.read_csv('annotated_df_orig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''compile annotated csv files from the most recent data set.'''\n",
    "os.chdir(annotated_csv_dir)\n",
    "\n",
    "annotated_df_lst = [] #list to be populated with dataframes \n",
    "\n",
    "for csv_name in os.listdir(): # iterate over all of the files in the directors\n",
    "    if 'in' in csv_name: #checkt to see if the .csv has the string 'in' \n",
    "        df_ = pd.read_csv(csv_name)\n",
    "        df_['in_object'] = np.ones(len(df_))\n",
    "        annotated_df_lst.append(df_)\n",
    "    if 'out' in csv_name:\n",
    "        df_ = pd.read_csv(csv_name)\n",
    "        df_['in_object'] = np.zeros(len(df_))\n",
    "        annotated_df_lst.append(df_)\n",
    "df_test_orig = pd.concat(annotated_df_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#categories to be used in training\n",
    "keep_cats = [ 'area', \n",
    "             'bbox_area',\n",
    "             'centroid-0',\n",
    "             'centroid-1',\n",
    "             'convex_area',\n",
    "             'eccentricity',\n",
    "             'equivalent_diameter',\n",
    "             'extent',\n",
    "             'local_centroid-0',\n",
    "             'local_centroid-1',\n",
    "             'major_axis_length',\n",
    "             'minor_axis_length',\n",
    "             'perimeter',\n",
    "             'solidity',\n",
    "             'inertia_tensor_eigvals-0',\n",
    "             'inertia_tensor_eigvals-1',\n",
    "             'moments_hu-0',\n",
    "             'moments_hu-1',\n",
    "             'moments_hu-2',\n",
    "             'moments_hu-3',\n",
    "             'moments_hu-4',\n",
    "             'moments_hu-5',\n",
    "             'moments_hu-6',\n",
    "             'in_object']\n",
    "\n",
    "'''set up dataframe from which to choos training and target params'''\n",
    "df_train = df_train_orig[keep_cats] # make a copy of original df. I am going to alter this a little bit in order to pull out train and test cats\n",
    "df_train = df_train.dropna() #get rid of of any entries that haf NA\n",
    "\n",
    "df_test = df_test_orig[keep_cats]\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "'''set up target parameter'''\n",
    "target_cat_name = 'in_object' #this is target category for the training the classifier\n",
    "\n",
    "'''define parameters and  target data in the training data'''\n",
    "x_train = df_train.drop('in_object', axis = 1)\n",
    "y_train = df_train[target_cat_name]\n",
    "\n",
    "'''define parameters and target data in the test set '''\n",
    "x_test = df_test.drop('in_object', axis = 1)\n",
    "y_test = df_test[target_cat_name]\n",
    "#x_test = df_\n",
    "#y_test = df_whole.[target_cat_name]\n",
    "\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = .25, random_state = 42) #'''split data into train and test sets'''\n",
    "\n",
    "'''this is a feature scaling step. This will normalize all of the data in order to pull everything into the same range'''\n",
    "sc_X = StandardScaler()\n",
    "x_train = sc_X.fit_transform(x_train)\n",
    "x_test = sc_X.transform(x_test)\n",
    "\n",
    "'''random forest classifier'''\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "model = GaussianNB()\n",
    "\n",
    "'''Train the model using the training sets y_pred=clf.predict(X_test)'''\n",
    "clf.fit(x_train,y_train)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.890625  precision:  0.9402985074626866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[51,  4],\n",
       "       [10, 63]], dtype=int64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''check how well model is performing'''\n",
    "y_pred = clf.predict(x_test)\n",
    "'''double check accuracy and precisiton of model'''\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print('accuracy: ', accuracy, ' precision: ', precision)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15873015873015872"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 / 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test new classifier\n",
    "\n",
    "Using the old classifier did an okay job but it was returning a lot of false positives. I think that it might be better to just use a new classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in an compile all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''compile annotated csv files from the most recent data set.'''\n",
    "os.chdir(annotated_csv_dir)\n",
    "\n",
    "annotated_df_lst = [] #list to be populated with dataframes \n",
    "\n",
    "for csv_name in os.listdir(): # iterate over all of the files in the directors\n",
    "    if 'in' in csv_name: #checkt to see if the .csv has the string 'in' \n",
    "        df_ = pd.read_csv(csv_name)\n",
    "        df_['in_object'] = np.ones(len(df_))\n",
    "        annotated_df_lst.append(df_)\n",
    "    if 'out' in csv_name:\n",
    "        df_ = pd.read_csv(csv_name)\n",
    "        df_['in_object'] = np.zeros(len(df_))\n",
    "        annotated_df_lst.append(df_)\n",
    "df_train = pd.concat(annotated_df_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#categories to be used in training\n",
    "keep_cats = [ 'area', \n",
    "             'bbox_area',\n",
    "             'centroid-0',\n",
    "             'centroid-1',\n",
    "             'convex_area',\n",
    "             'eccentricity',\n",
    "             'equivalent_diameter',\n",
    "             'extent',\n",
    "             'local_centroid-0',\n",
    "             'local_centroid-1',\n",
    "             'major_axis_length',\n",
    "             'minor_axis_length',\n",
    "             'perimeter',\n",
    "             'solidity',\n",
    "             'inertia_tensor_eigvals-0',\n",
    "             'inertia_tensor_eigvals-1',\n",
    "             'moments_hu-0',\n",
    "             'moments_hu-1',\n",
    "             'moments_hu-2',\n",
    "             'moments_hu-3',\n",
    "             'moments_hu-4',\n",
    "             'moments_hu-5',\n",
    "             'moments_hu-6',\n",
    "             'in_object']\n",
    "\n",
    "'''set up dataframe from which to choos training and target params'''\n",
    "df_train = df_train_orig[keep_cats] # make a copy of original df. I am going to alter this a little bit in order to pull out train and test cats\n",
    "df_train = df_train.dropna() #get rid of of any entries that haf NA\n",
    "\n",
    "\n",
    "#'''set up target parameter'''\n",
    "#target_cat_name = 'in_object' #this is target category for the training the classifier\n",
    "\n",
    "'''define parameters and  target data in the training data'''\n",
    "x_train = df_train.drop('in_object', axis = 1)\n",
    "y_train = df_train[target_cat_name]\n",
    "\n",
    "#'''define parameters and target data in the test set '''\n",
    "#x_test = df_test.drop('in_object', axis = 1)\n",
    "#y_test = df_test[target_cat_name]\n",
    "#x_test = df_\n",
    "#y_test = df_whole.[target_cat_name]\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = .25, random_state = 42) #'''split data into train and test sets'''\n",
    "\n",
    "'''this is a feature scaling step. This will normalize all of the data in order to pull everything into the same range'''\n",
    "sc_X = StandardScaler()\n",
    "x_train = sc_X.fit_transform(x_train)\n",
    "x_test = sc_X.transform(x_test)\n",
    "\n",
    "'''random forest classifier'''\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "model = GaussianNB()\n",
    "\n",
    "'''Train the model using the training sets y_pred=clf.predict(X_test)'''\n",
    "clf.fit(x_train,y_train)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9444444444444444  precision:  0.9230769230769231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27,  2],\n",
       "       [ 1, 24]], dtype=int64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''check how well model is performing'''\n",
    "y_pred = clf.predict(x_test)\n",
    "'''double check accuracy and precisiton of model'''\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print('accuracy: ', accuracy, ' precision: ', precision)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This newly trained classifier is doing a much better job. Making sure that cell profiler outputs to 16bit images speeds up things considerably as I don't have to identify objects in the df can just use the label value in the image. From here on I think that this will be a much better avenue then trying to go through and use an old classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_analysis",
   "language": "python",
   "name": "img_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
